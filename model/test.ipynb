{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExtractCell import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image2Sudoku(r\"5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = img.getCells()\n",
    "for key, value in cells.items():\n",
    "    if value is not None:\n",
    "        newValue = cv2.resize(value, (50,50))\n",
    "        cv2.imwrite( 'T' + key + '.png', newValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['value', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [value, image]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "images = []\n",
    "labels = []\n",
    "for subdir, dirs, files in os.walk('data'):\n",
    "    for subdir, dirs, files in os.walk(subdir):\n",
    "        if files:\n",
    "            label = subdir[-1:]\n",
    "            for file in files:\n",
    "                imagePath = subdir + \"\\\\\" + file\n",
    "                images.append(cv2.imread(imagePath).flatten())\n",
    "                labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.asarray(images)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "KneighboursModel_5 = KNeighborsClassifier(n_neighbors=3)\n",
    "SVCModelLinear = SVC(kernel='rbf', C=5, gamma=5)\n",
    "NeuralModel = MLPClassifier(solver='lbfgs',\n",
    "                            hidden_layer_sizes=(5, 4),\n",
    "                            activation='identity',\n",
    "                            random_state=0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 4), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=0, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KneighboursModel_5.fit(images, labels)\n",
    "SVCModelLinear.fit(images, labels)\n",
    "NeuralModel.fit(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KneighboursModel_5.score(X_test, y_test)\n",
    "s = SVCModelLinear.score(X_test, y_test)\n",
    "n = NeuralModel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\\T0.png\n",
      "['1']\n",
      "test\\T1.png\n",
      "['2']\n",
      "test\\T13.png\n",
      "['6']\n",
      "test\\T17.png\n",
      "['4']\n",
      "test\\T19.png\n",
      "['3']\n",
      "test\\T2.png\n",
      "['9']\n",
      "test\\T21.png\n",
      "['9']\n",
      "test\\T25.png\n",
      "['7']\n",
      "test\\T27.png\n",
      "['9']\n",
      "test\\T29.png\n",
      "['8']\n",
      "test\\T30.png\n",
      "['4']\n",
      "test\\T32.png\n",
      "['4']\n",
      "test\\T36.png\n",
      "['1']\n",
      "test\\T38.png\n",
      "['7']\n",
      "test\\T40.png\n",
      "['2']\n",
      "test\\T42.png\n",
      "['4']\n",
      "test\\T44.png\n",
      "['3']\n",
      "test\\T48.png\n",
      "['3']\n",
      "test\\T50.png\n",
      "['6']\n",
      "test\\T51.png\n",
      "['5']\n",
      "test\\T53.png\n",
      "['7']\n",
      "test\\T55.png\n",
      "['6']\n",
      "test\\T59.png\n",
      "['7']\n",
      "test\\T6.png\n",
      "['3']\n",
      "test\\T61.png\n",
      "['9']\n",
      "test\\T63.png\n",
      "['4']\n",
      "test\\T67.png\n",
      "['3']\n",
      "test\\T74.png\n",
      "['8']\n",
      "test\\T78.png\n",
      "['5']\n",
      "test\\T79.png\n",
      "['4']\n",
      "test\\T80.png\n",
      "['4']\n"
     ]
    }
   ],
   "source": [
    "for subdir, dirs, files in os.walk('test'):\n",
    "    for file in files:\n",
    "        imagePath = subdir + \"\\\\\" + file\n",
    "        print(imagePath)\n",
    "        a = cv2.imread(imagePath).flatten()\n",
    "        result = KneighboursModel_5.predict([a])\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
